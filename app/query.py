from flask import jsonify, request
from config.chromadb_config import vector_store
from langchain.chat_models import ChatOpenAI


def askAI(query_text, prompt_template):
    #retrieve vector store
    db = vector_store
    
    #perform similarity search based on query text get 3 chunks for now
    results = db.similarity_search(query_text, k=3)
    
    #combine text from all results
    combine_text = "\n\n- -\n\n".join([doc.page_content for doc in results])

    #combine text and query text into prompt
    prompt = prompt_template.format(context=combine_text, question=query_text)

    #initialise model
    model = ChatOpenAI()

    #get response from model
    response = model.predict(prompt)

    #return response and context
    return response, combine_text


def query():
    #get query text from request
    query_text = request.json["query_text"]

    #template for prompt
    prompt_template = """"
    Answer the following question based on the following context from retrieved documents: {context}
    If a piece of information from context is not related to the question, please ignore it.
    Question: {question}
    """

    #get response from model
    response = askAI(query_text, prompt_template)

    #return response and context
    return jsonify({"response": response, "context": context})

def summary():
    #get query text from request
    query_text = request.json["query_text"]

    #template for prompt
    prompt_template = """"
    Create a summary of the query generated by the user using the following context as a guide
    for what information to summaries: {context}
    If a piece of information from context is not related to the question, please ignore it.
    query: {question}
    """

    response, context = askAI(query_text, prompt_template)

    #return response
    return jsonify({"response": response, "context": context})


def mcq():
    #get query text from request
    query_text = request.json["query_text"]
    
    #template for prompt
    prompt_template = """"
    Create a MCQ of the query generated by the user using the following context as a guide
    for what information to include in each question: {context}
    If a piece of information from context is not related to the question, please ignore it.
    generate 10 question including the 4 options and the correct answer
    query: {question}
    """

    response, context = askAI(query_text, prompt_template)

    #return response
    return jsonify({"response": response, "context": context})